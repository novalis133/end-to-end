# RAG Service Backend Integration Guide

This guide explains how to integrate the RAG (Retrieval-Augmented Generation) service into your backend application.

## Prerequisites

Before using the RAG service, ensure you have:
1. MongoDB running locally or accessible via the configured URI
2. Ollama server running with the Mistral model
3. Environment variables properly configured (see `.env` example below)

## Environment Configuration

The service requires the following environment variables:

```env
# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
MODEL_NAME=mistral

# MongoDB Configuration
MONGO_URI=mongodb://localhost:27017
DB_NAME=llm_papers

# Paper Categories and Keywords
PAPER_CATEGORIES=cs.CL,cs.AI
KEYWORDS=llm,transformer,language model,generative ai
```

## Core Functions

### 1. Content Processing

Use this function to add new content (papers, repositories, documentation) to the system.

```python
from rag_service_interface import RAGServiceInterface, ContentMetadata
from datetime import datetime

# Initialize the service
rag_service = RAGServiceInterface()

# Example: Adding a new paper
metadata = ContentMetadata(
    content_id="",  # Will be generated by the service
    content_type="paper",
    title="New LLM Research",
    source_url="https://arxiv.org/abs/1234.5678",
    authors=["Author1", "Author2"],
    published_date=datetime.now(),
    categories=["cs.CL", "cs.AI"],
    tags=["llm", "transformer"]
)

# Process the content
result = rag_service.process_content(
    content="Full paper text here...",
    metadata=metadata
)

# The result will contain:
# {
#     'content_id': 'generated-uuid',
#     'status': 'processed',
#     'chunks': [...],
#     'processing_time': 0.0
# }
```

### 2. Content Generation

Generate new content (tweets, summaries) based on existing content in the system.

```python
from rag_service_interface import GenerationRequest

# Example: Generating a tweet
generation_request = GenerationRequest(
    content_id=result['content_id'],
    prompt="Generate a tweet about this paper",
    style="technical",
    max_length=280,
    include_source=True
)

# Generate the content
tweet = rag_service.generate_content(generation_request)

# The response will contain:
# {
#     'generated_text': 'Generated tweet text...',
#     'source_url': 'https://arxiv.org/abs/1234.5678',
#     'metadata': {
#         'content_id': '...',
#         'style': 'technical',
#         'generation_time': '2024-01-01T12:00:00'
#     }
# }
```

### 3. Content Search

Search for similar content in the system.

```python
# Example: Finding similar papers
similar_papers = rag_service.search_similar_content(
    query="transformer architecture improvements",
    content_type="paper",
    limit=5
)

# The response will contain a list of similar documents:
# [
#     {
#         'content_id': '...',
#         'score': 0.95,
#         'content': 'Paper content...'
#     },
#     ...
# ]
```

### 4. Content Status Check

Monitor the status of content processing.

```python
# Example: Checking content status
status = rag_service.get_content_status(content_id="some-content-id")

# The response will contain:
# {
#     'status': 'processed',
#     'progress': 1.0,
#     'last_updated': '2024-01-01T12:00:00',
#     'error': None
# }
```

## Error Handling

The service includes comprehensive error handling. All functions will:
1. Return appropriate error messages in the response
2. Log errors for debugging
3. Maintain system stability even when errors occur

Common error scenarios:
- Invalid content format
- Database connection issues
- Ollama service unavailability
- Invalid content IDs

## Best Practices

1. **Content Processing**:
   - Always provide complete metadata
   - Use appropriate content types
   - Include source URLs when available

2. **Content Generation**:
   - Be specific in your prompts
   - Use appropriate style parameters
   - Set reasonable length limits

3. **Content Search**:
   - Use specific queries
   - Filter by content type when possible
   - Adjust limit based on your needs

4. **Error Handling**:
   - Always check the status of processed content
   - Implement retry logic for transient errors
   - Log errors appropriately

## Example Integration

Here's a complete example of integrating the RAG service into a backend application:

```python
from rag_service_interface import RAGServiceInterface, ContentMetadata, GenerationRequest
from datetime import datetime

class BackendService:
    def __init__(self):
        self.rag_service = RAGServiceInterface()

    def process_new_paper(self, paper_text: str, paper_metadata: dict):
        metadata = ContentMetadata(
            content_type="paper",
            title=paper_metadata["title"],
            source_url=paper_metadata["url"],
            authors=paper_metadata["authors"],
            published_date=datetime.now(),
            categories=paper_metadata["categories"],
            tags=paper_metadata["tags"]
        )
        
        result = self.rag_service.process_content(
            content=paper_text,
            metadata=metadata
        )
        
        return result["content_id"]

    def generate_tweet(self, content_id: str):
        request = GenerationRequest(
            content_id=content_id,
            prompt="Generate an engaging tweet about this paper",
            style="technical",
            max_length=280,
            include_source=True
        )
        
        return self.rag_service.generate_content(request)

    def find_related_papers(self, query: str, limit: int = 5):
        return self.rag_service.search_similar_content(
            query=query,
            content_type="paper",
            limit=limit
        )
```

## Support

For additional support or questions:
1. Check the system logs for detailed error information
2. Review the source code documentation
3. Contact the development team for specific issues 